{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# set environment variable here.\n",
    "os.environ[\"nnUNet_preprocessed\"] = \"/home/bhatti_uhn/nnUNet_preprocessed\"\n",
    "os.environ[\"nnUNet_results\"] = \"/home/bhatti_uhn/nnUNet_results\"\n",
    "os.environ[\"nnUNet_raw\"] = \"/home/bhatti_uhn/nnUNet_raw\"\n",
    "\n",
    "# Ensure that environment variables are set correctly # from run_training.py\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from nnunetv2.dataset_conversion import generate_dataset_json\n",
    "from nnunetv2.run.run_training import run_training_entry\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "base_dir = '/home/bhatti_uhn/Dataset/UHN-MedImg3D-ML-quiz'\n",
    "nnunet_base = '/home/bhatti_uhn/nnUNet_raw/Dataset876_UHNMedImg3D'\n",
    "\n",
    "images_tr_dir = os.path.join(nnunet_base, 'imagesTr')\n",
    "labels_tr_dir = os.path.join(nnunet_base, 'labelsTr')\n",
    "images_ts_dir = os.path.join(nnunet_base, 'imagesTs')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(images_tr_dir, exist_ok=True)\n",
    "os.makedirs(labels_tr_dir, exist_ok=True)\n",
    "os.makedirs(images_ts_dir, exist_ok=True)\n",
    "    \n",
    "\n",
    "trainSrc = os.path.join(base_dir, 'train')\n",
    "testSrc = os.path.join(base_dir, 'test')\n",
    "\n",
    "# list subdirectories of trainSrc # remove .DS_Store\n",
    "train_subdirs = [sdir for sdir in os.listdir(trainSrc) if not sdir.startswith('.')]\n",
    "train_subdirs = sorted(train_subdirs)\n",
    "train_subdirs\n",
    "\n",
    "def copy_files_to_raw(images_tr_dir, labels_tr_dir, trainSrc, train_subdirs):\n",
    "\n",
    "    for i, subdir in enumerate(train_subdirs):\n",
    "        print(f\"Processing {subdir}...\")\n",
    "\n",
    "    # create path for reading subdirectories\n",
    "        train_subdir = os.path.join(trainSrc, subdir)\n",
    "\n",
    "    # list files in subdirectory\n",
    "        files = [s for s in sorted(os.listdir(train_subdir)) if not s.startswith('.')]\n",
    "\n",
    "    # separate images and labels files: image: 'quiz_2_002_0000.nii.gz', and label: 'quiz_2_002.nii.gz'\n",
    "        for j, fileName in enumerate(files):\n",
    "            if len(fileName.split('_')) == 4: # assuming quiz_subType_patID is a valid CASE_ID. and 0000 is the modality.\n",
    "                fileNameSplit = fileName.split('_')\n",
    "                logging.info(f\"Processing {fileNameSplit}\")\n",
    "\n",
    "                newFileName = fileNameSplit[0] + '_' + fileNameSplit[1] + '_' + fileNameSplit[2] + '_' + fileNameSplit[3]\n",
    "                tr_copyPath = os.path.join(train_subdir, fileName)\n",
    "\n",
    "                logging.info(f\"Copying {tr_copyPath} to {images_tr_dir}\")\n",
    "                shutil.copy(tr_copyPath, images_tr_dir)\n",
    "                # rename the file\n",
    "                # os.rename(os.path.join(images_tr_dir, fileName), os.path.join(images_tr_dir, newFileName))\n",
    "\n",
    "            elif len(fileName.split('_')) == 3:\n",
    "                fileNameSplit = fileName.split('_')\n",
    "                newFileName = fileNameSplit[0] + '_' + fileNameSplit[1] + '_' + fileNameSplit[2]\n",
    "\n",
    "                shutil.copy(os.path.join(train_subdir, fileName), labels_tr_dir)\n",
    "                # rename the file\n",
    "                # os.rename(os.path.join(labels_tr_dir, fileName), os.path.join(labels_tr_dir, newFileName))\n",
    "\n",
    "            else: \n",
    "                raise ValueError(f\"File {fileName} does not match the expected format.\")\n",
    "\n",
    "\n",
    "def copy_testFiles_to_raw(images_ts_dir, testSrc):\n",
    "\n",
    "    files = [s for s in sorted(os.listdir(testSrc)) if not s.startswith('.')]\n",
    "\n",
    "    for j, fileName in enumerate(files):\n",
    "        shutil.copy(os.path.join(testSrc, fileName), images_ts_dir)\n",
    "\n",
    "# ## uncomment to run ###\n",
    "# copy_files_to_raw(images_tr_dir, labels_tr_dir, trainSrc, train_subdirs)\n",
    "# copy_testFiles_to_raw(images_ts_dir, testSrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting. label integrity check fails. Expected: [np.int64(0), np.int64(1), np.int64(2)] Found: [0.        1.0000153 2.       ]\n",
    "# fixing the label files\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "# Function to correct labels\n",
    "def correct_labels(image):\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    array = np.where(np.isclose(array, 1.0000153), 1, array)  # Correcting the label value\n",
    "    array = np.int64(array)\n",
    "    corrected_image = sitk.GetImageFromArray(array)\n",
    "    corrected_image.CopyInformation(image)\n",
    "    return corrected_image\n",
    "\n",
    "# Load the problematic image\n",
    "def correct_all_type_labels(labels_tr_dir):\n",
    "    labelImagesInDir = [sdir for sdir in sorted(os.listdir(labels_tr_dir)) if not sdir.startswith('.')]\n",
    "\n",
    "    for labelImgIdx, labelImg in enumerate(labelImagesInDir):\n",
    "        imagePath = os.path.join(labels_tr_dir, labelImg)\n",
    "        image = sitk.ReadImage(imagePath)\n",
    "\n",
    "    # Correct the labels\n",
    "        corrected_image = correct_labels(image)\n",
    "        sitk.WriteImage(corrected_image, imagePath)\n",
    "\n",
    "\n",
    "# ## uncomment to run ###\n",
    "# correct_all_type_labels(labels_tr_dir)\n",
    "\n",
    "# create dataset.json\n",
    "channel_names = {0: \"CT\"}\n",
    "\n",
    "labels = {\n",
    "    'background': 0,\n",
    "    'pancreas': 1,\n",
    "    'lesion': 2\n",
    "}\n",
    "\n",
    "num_training_cases = len(os.listdir(images_tr_dir))\n",
    "file_ending = '.nii.gz'\n",
    "\n",
    "# ## uncomment to run ###\n",
    "# generate_dataset_json.generate_dataset_json(nnunet_base, channel_names, labels, num_training_cases, file_ending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spacing(image_path, seg_path):\n",
    "    # Load the image and segmentation\n",
    "    image = sitk.ReadImage(image_path)\n",
    "    seg = sitk.ReadImage(seg_path)\n",
    "    \n",
    "    # Get the spacing from the image\n",
    "    image_spacing = image.GetSpacing()\n",
    "    seg_spacing = seg.GetSpacing()\n",
    "    \n",
    "    # Compare and correct spacing if needed\n",
    "    if not np.allclose(image_spacing, seg_spacing, atol=1e-7):\n",
    "        print(f\"Correcting spacing for {seg_path}\")\n",
    "        seg.SetSpacing(image_spacing)\n",
    "        \n",
    "        # Save the corrected segmentation\n",
    "        sitk.WriteImage(seg, seg_path)\n",
    "        print(f\"Corrected segmentation saved to {seg_path}\")\n",
    "\n",
    "# Correct spacing for the segmentation files\n",
    "# list all files under imagesTr\n",
    "\n",
    "#  ## uncomment to run ###\n",
    "# imageFilesInDir = [sdir for sdir in sorted(os.listdir(images_tr_dir)) if not sdir.startswith('.')]\n",
    "\n",
    "# for imageIdx, image in enumerate(imageFilesInDir):\n",
    "#     imgPath = os.path.join(images_tr_dir, image)\n",
    "#     segPath = os.path.join(labels_tr_dir, image.replace('_0000', ''))\n",
    "\n",
    "#     correct_spacing(imgPath, segPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-08-02 21:13:48.724400: do_dummy_2d_data_aug: False\n",
      "2024-08-02 21:13:48.727896: Using splits from existing split file: /home/bhatti_uhn/nnUNet_preprocessed/Dataset876_UHNMedImg3D/splits_final.json\n",
      "2024-08-02 21:13:48.728107: The split file contains 5 splits.\n",
      "2024-08-02 21:13:48.728178: Desired fold for training: 0\n",
      "2024-08-02 21:13:48.728245: This split has 201 training and 51 validation cases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhatti_uhn/nnU-net/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pin_memory on device 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Run the training entry function\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mrun_training_entry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/bhatti_uhn/nnU-net/nnunetv2/run/run_training.py:275\u001b[0m, in \u001b[0;36mrun_training_entry\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 275\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_name_or_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m             \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_compressed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnpz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_checkpointing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/bhatti_uhn/nnU-net/nnunetv2/run/run_training.py:211\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(dataset_name_or_id, configuration, fold, trainer_class_name, plans_identifier, pretrained_weights, num_gpus, use_compressed_data, export_validation_probabilities, continue_training, only_run_validation, disable_checkpointing, val_with_best, device)\u001b[0m\n\u001b[1;32m    208\u001b[0m     cudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m only_run_validation:\n\u001b[0;32m--> 211\u001b[0m     \u001b[43mnnunet_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_with_best:\n\u001b[1;32m    214\u001b[0m     nnunet_trainer\u001b[38;5;241m.\u001b[39mload_checkpoint(join(nnunet_trainer\u001b[38;5;241m.\u001b[39moutput_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_best.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/home/bhatti_uhn/nnU-net/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1362\u001b[0m, in \u001b[0;36mnnUNetTrainer.run_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_training\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1362\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs):\n\u001b[1;32m   1365\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_epoch_start()\n",
      "File \u001b[0;32m/home/bhatti_uhn/nnU-net/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:903\u001b[0m, in \u001b[0;36mnnUNetTrainer.on_train_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_start\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;66;03m# dataloaders must be instantiated here (instead of __init__) because they need access to the training data\u001b[39;00m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;66;03m# which may not be present  when doing inference\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwas_initialized:\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[0;32m/home/bhatti_uhn/nnU-net/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:696\u001b[0m, in \u001b[0;36mnnUNetTrainer.get_dataloaders\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m     mt_gen_val \u001b[38;5;241m=\u001b[39m NonDetMultiThreadedAugmenter(data_loader\u001b[38;5;241m=\u001b[39mdl_val,\n\u001b[1;32m    691\u001b[0m                                               transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, num_processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, allowed_num_processes \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m    692\u001b[0m                                               num_cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m3\u001b[39m, allowed_num_processes \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m), seeds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    693\u001b[0m                                               pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    694\u001b[0m                                               wait_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.002\u001b[39m)\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# # let's get this party started\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmt_gen_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(mt_gen_val)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mt_gen_train, mt_gen_val\n",
      "File \u001b[0;32m/home/uhn_venv/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py:196\u001b[0m, in \u001b[0;36mNonDetMultiThreadedAugmenter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start()\n\u001b[0;32m--> 196\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_next_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m item\n",
      "File \u001b[0;32m/home/uhn_venv/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py:188\u001b[0m, in \u001b[0;36mNonDetMultiThreadedAugmenter.__get_next_item\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_loop_queue\u001b[38;5;241m.\u001b[39mtask_done()\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m         \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m item\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "# Define the necessary arguments\n",
    "args = [\n",
    "    \"script_name\",  # This is a placeholder for the script name\n",
    "    \"Dataset876_UHNMedImg3D\",  # dataset_name_or_id\n",
    "    \"3d_fullres\",  # configuration\n",
    "    f\"{fold}\",  # fold\n",
    "    # '-tr', 'nnUNetTrainer',  # optional: trainer_class_name\n",
    "    # '-p', 'nnUNetPlans',  # optional: plans_identifier\n",
    "]\n",
    "\n",
    "# Set sys.argv to the list of arguments\n",
    "sys.argv = args\n",
    "\n",
    "# Run the training entry function\n",
    "run_training_entry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "Fingerprint extraction...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uhn_venv/bin/nnUNetv2_plan_and_preprocess\", line 8, in <module>\n",
      "    sys.exit(plan_and_preprocess_entry())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bhatti_uhn/nnU-net/nnunetv2/experiment_planning/plan_and_preprocess_entrypoints.py\", line 180, in plan_and_preprocess_entry\n",
      "    extract_fingerprints(args.d, args.fpe, args.npfp, args.verify_dataset_integrity, args.clean, args.verbose)\n",
      "  File \"/home/bhatti_uhn/nnU-net/nnunetv2/experiment_planning/plan_and_preprocess_api.py\", line 47, in extract_fingerprints\n",
      "    extract_fingerprint_dataset(d, fingerprint_extractor_class, num_processes, check_dataset_integrity, clean,\n",
      "  File \"/home/bhatti_uhn/nnU-net/nnunetv2/experiment_planning/plan_and_preprocess_api.py\", line 26, in extract_fingerprint_dataset\n",
      "    dataset_name = convert_id_to_dataset_name(dataset_id)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bhatti_uhn/nnU-net/nnunetv2/utilities/dataset_name_id_conversion.py\", line 48, in convert_id_to_dataset_name\n",
      "    raise RuntimeError(f\"Could not find a dataset with the ID {dataset_id}. Make sure the requested dataset ID \"\n",
      "RuntimeError: Could not find a dataset with the ID 876. Make sure the requested dataset ID exists and that nnU-Net knows where raw and preprocessed data are located (see Documentation - Installation). Here are your currently defined folders:\n",
      "nnUNet_preprocessed=None\n",
      "nnUNet_results=None\n",
      "nnUNet_raw=None\n",
      "If something is not right, adapt your environment variables.\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_plan_and_preprocess -d 876 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming your dataset has 'images' and 'labels' subdirectories\n",
    "# move_and_rename_files(os.path.join(base_dir, 'images'), images_tr_dir, 'patient')\n",
    "# move_and_rename_files(os.path.join(base_dir, 'labels'), labels_tr_dir, 'patient', is_label=True)\n",
    "\n",
    "# # Create dataset.json\n",
    "# dataset_json = {\n",
    "#     \"name\": \"UHNMedImg3D\",\n",
    "#     \"description\": \"UHN Medical Imaging 3D Machine Learning Quiz Dataset\",\n",
    "#     \"tensorImageSize\": \"4D\",\n",
    "#     \"reference\": \"\",\n",
    "#     \"licence\": \"\",\n",
    "#     \"release\": \"0.0\",\n",
    "#     \"modality\": {\n",
    "#         \"0\": \"CT\"\n",
    "#     },\n",
    "#     \"labels\": {\n",
    "#         \"0\": \"background\",\n",
    "#         \"1\": \"label1\",\n",
    "#         \"2\": \"label2\"\n",
    "#     },\n",
    "#     \"numTraining\": len(os.listdir(images_tr_dir)),\n",
    "#     \"numTest\": 0,  # Update this if you have test images\n",
    "#     \"training\": [\n",
    "#         {\n",
    "#             \"image\": f\"./imagesTr/patient_{i+1:03d}_0000.nii.gz\",\n",
    "#             \"label\": f\"./labelsTr/patient_{i+1:03d}.nii.gz\"\n",
    "#         } for i in range(len(os.listdir(images_tr_dir)))\n",
    "#     ],\n",
    "#     \"test\": []  # Update this if you have test images\n",
    "# }\n",
    "\n",
    "# # Save dataset.json\n",
    "# with open(os.path.join(nnunet_base, 'dataset.json'), 'w') as f:\n",
    "#     json.dump(dataset_json, f, indent=4)\n",
    "\n",
    "# print(\"Dataset arranged successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uhn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
