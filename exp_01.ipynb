{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# set environment variable here.\n",
    "os.environ[\"nnUNet_preprocessed\"] = \"/home/bhatti_uhn/nnUNet_preprocessed\"\n",
    "os.environ[\"nnUNet_results\"] = \"/home/bhatti_uhn/nnUNet_results\"\n",
    "os.environ[\"nnUNet_raw\"] = \"/home/bhatti_uhn/nnUNet_raw\"\n",
    "\n",
    "# Ensure that environment variables are set correctly # from run_training.py\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from nnunetv2.dataset_conversion import generate_dataset_json\n",
    "from nnunetv2.run.run_training import run_training_entry\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "base_dir = '/home/bhatti_uhn/Dataset/UHN-MedImg3D-ML-quiz'\n",
    "nnunet_base = '/home/bhatti_uhn/nnUNet_raw/Dataset876_UHNMedImg3D'\n",
    "\n",
    "images_tr_dir = os.path.join(nnunet_base, 'imagesTr')\n",
    "labels_tr_dir = os.path.join(nnunet_base, 'labelsTr')\n",
    "images_ts_dir = os.path.join(nnunet_base, 'imagesTs')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(images_tr_dir, exist_ok=True)\n",
    "os.makedirs(labels_tr_dir, exist_ok=True)\n",
    "os.makedirs(images_ts_dir, exist_ok=True)\n",
    "    \n",
    "\n",
    "trainSrc = os.path.join(base_dir, 'train')\n",
    "testSrc = os.path.join(base_dir, 'test')\n",
    "\n",
    "# list subdirectories of trainSrc # remove .DS_Store\n",
    "train_subdirs = [sdir for sdir in os.listdir(trainSrc) if not sdir.startswith('.')]\n",
    "train_subdirs = sorted(train_subdirs)\n",
    "train_subdirs\n",
    "\n",
    "def copy_files_to_raw(images_tr_dir, labels_tr_dir, trainSrc, train_subdirs):\n",
    "\n",
    "    for i, subdir in enumerate(train_subdirs):\n",
    "        print(f\"Processing {subdir}...\")\n",
    "\n",
    "    # create path for reading subdirectories\n",
    "        train_subdir = os.path.join(trainSrc, subdir)\n",
    "\n",
    "    # list files in subdirectory\n",
    "        files = [s for s in sorted(os.listdir(train_subdir)) if not s.startswith('.')]\n",
    "\n",
    "    # separate images and labels files: image: 'quiz_2_002_0000.nii.gz', and label: 'quiz_2_002.nii.gz'\n",
    "        for j, fileName in enumerate(files):\n",
    "            if len(fileName.split('_')) == 4: # assuming quiz_subType_patID is a valid CASE_ID. and 0000 is the modality.\n",
    "                fileNameSplit = fileName.split('_')\n",
    "                logging.info(f\"Processing {fileNameSplit}\")\n",
    "\n",
    "                newFileName = fileNameSplit[0] + '_' + fileNameSplit[1] + '_' + fileNameSplit[2] + '_' + fileNameSplit[3]\n",
    "                tr_copyPath = os.path.join(train_subdir, fileName)\n",
    "\n",
    "                logging.info(f\"Copying {tr_copyPath} to {images_tr_dir}\")\n",
    "                shutil.copy(tr_copyPath, images_tr_dir)\n",
    "                # rename the file\n",
    "                # os.rename(os.path.join(images_tr_dir, fileName), os.path.join(images_tr_dir, newFileName))\n",
    "\n",
    "            elif len(fileName.split('_')) == 3:\n",
    "                fileNameSplit = fileName.split('_')\n",
    "                newFileName = fileNameSplit[0] + '_' + fileNameSplit[1] + '_' + fileNameSplit[2]\n",
    "\n",
    "                shutil.copy(os.path.join(train_subdir, fileName), labels_tr_dir)\n",
    "                # rename the file\n",
    "                # os.rename(os.path.join(labels_tr_dir, fileName), os.path.join(labels_tr_dir, newFileName))\n",
    "\n",
    "            else: \n",
    "                raise ValueError(f\"File {fileName} does not match the expected format.\")\n",
    "\n",
    "\n",
    "def copy_testFiles_to_raw(images_ts_dir, testSrc):\n",
    "\n",
    "    files = [s for s in sorted(os.listdir(testSrc)) if not s.startswith('.')]\n",
    "\n",
    "    for j, fileName in enumerate(files):\n",
    "        shutil.copy(os.path.join(testSrc, fileName), images_ts_dir)\n",
    "\n",
    "# ## uncomment to run ###\n",
    "# copy_files_to_raw(images_tr_dir, labels_tr_dir, trainSrc, train_subdirs)\n",
    "# copy_testFiles_to_raw(images_ts_dir, testSrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting. label integrity check fails. Expected: [np.int64(0), np.int64(1), np.int64(2)] Found: [0.        1.0000153 2.       ]\n",
    "# fixing the label files\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "# Function to correct labels\n",
    "def correct_labels(image):\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    array = np.where(np.isclose(array, 1.0000153), 1, array)  # Correcting the label value\n",
    "    array = np.int64(array)\n",
    "    corrected_image = sitk.GetImageFromArray(array)\n",
    "    corrected_image.CopyInformation(image)\n",
    "    return corrected_image\n",
    "\n",
    "# Load the problematic image\n",
    "def correct_all_type_labels(labels_tr_dir):\n",
    "    labelImagesInDir = [sdir for sdir in sorted(os.listdir(labels_tr_dir)) if not sdir.startswith('.')]\n",
    "\n",
    "    for labelImgIdx, labelImg in enumerate(labelImagesInDir):\n",
    "        imagePath = os.path.join(labels_tr_dir, labelImg)\n",
    "        image = sitk.ReadImage(imagePath)\n",
    "\n",
    "    # Correct the labels\n",
    "        corrected_image = correct_labels(image)\n",
    "        sitk.WriteImage(corrected_image, imagePath)\n",
    "\n",
    "\n",
    "# ## uncomment to run ###\n",
    "# correct_all_type_labels(labels_tr_dir)\n",
    "\n",
    "# create dataset.json\n",
    "channel_names = {0: \"CT\"}\n",
    "\n",
    "labels = {\n",
    "    'background': 0,\n",
    "    'pancreas': 1,\n",
    "    'lesion': 2\n",
    "}\n",
    "\n",
    "num_training_cases = len(os.listdir(images_tr_dir))\n",
    "file_ending = '.nii.gz'\n",
    "\n",
    "# ## uncomment to run ###\n",
    "# generate_dataset_json.generate_dataset_json(nnunet_base, channel_names, labels, num_training_cases, file_ending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spacing(image_path, seg_path):\n",
    "    # Load the image and segmentation\n",
    "    image = sitk.ReadImage(image_path)\n",
    "    seg = sitk.ReadImage(seg_path)\n",
    "    \n",
    "    # Get the spacing from the image\n",
    "    image_spacing = image.GetSpacing()\n",
    "    seg_spacing = seg.GetSpacing()\n",
    "    \n",
    "    # Compare and correct spacing if needed\n",
    "    if not np.allclose(image_spacing, seg_spacing, atol=1e-7):\n",
    "        print(f\"Correcting spacing for {seg_path}\")\n",
    "        seg.SetSpacing(image_spacing)\n",
    "        \n",
    "        # Save the corrected segmentation\n",
    "        sitk.WriteImage(seg, seg_path)\n",
    "        print(f\"Corrected segmentation saved to {seg_path}\")\n",
    "\n",
    "# Correct spacing for the segmentation files\n",
    "# list all files under imagesTr\n",
    "\n",
    "#  ## uncomment to run ###\n",
    "# imageFilesInDir = [sdir for sdir in sorted(os.listdir(images_tr_dir)) if not sdir.startswith('.')]\n",
    "\n",
    "# for imageIdx, image in enumerate(imageFilesInDir):\n",
    "#     imgPath = os.path.join(images_tr_dir, image)\n",
    "#     segPath = os.path.join(labels_tr_dir, image.replace('_0000', ''))\n",
    "\n",
    "#     correct_spacing(imgPath, segPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-08-03 17:10:32.915253: do_dummy_2d_data_aug: False\n",
      "2024-08-03 17:10:32.916281: Using splits from existing split file: /home/bhatti_uhn/nnUNet_preprocessed/Dataset876_UHNMedImg3D/splits_final.json\n",
      "2024-08-03 17:10:32.916439: The split file contains 5 splits.\n",
      "2024-08-03 17:10:32.916474: Desired fold for training: 0\n",
      "2024-08-03 17:10:32.916503: This split has 201 training and 51 validation cases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhatti_uhn/nnU-net/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "SegClsNet.__init__() got multiple values for argument 'n_stages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Run the training entry function\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mrun_training_entry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/bhatti_uhn/nnU-net/nnunetv2/run/run_training.py:275\u001b[0m, in \u001b[0;36mrun_training_entry\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 275\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_name_or_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m             \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_compressed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnpz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_checkpointing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/bhatti_uhn/nnU-net/nnunetv2/run/run_training.py:211\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(dataset_name_or_id, configuration, fold, trainer_class_name, plans_identifier, pretrained_weights, num_gpus, use_compressed_data, export_validation_probabilities, continue_training, only_run_validation, disable_checkpointing, val_with_best, device)\u001b[0m\n\u001b[1;32m    208\u001b[0m     cudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m only_run_validation:\n\u001b[0;32m--> 211\u001b[0m     \u001b[43mnnunet_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_with_best:\n\u001b[1;32m    214\u001b[0m     nnunet_trainer\u001b[38;5;241m.\u001b[39mload_checkpoint(join(nnunet_trainer\u001b[38;5;241m.\u001b[39moutput_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_best.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/home/bhatti_uhn/nnU-net/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1362\u001b[0m, in \u001b[0;36mnnUNetTrainer.run_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_training\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1362\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs):\n\u001b[1;32m   1365\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_epoch_start()\n",
      "File \u001b[0;32m/home/bhatti_uhn/nnU-net/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:906\u001b[0m, in \u001b[0;36mnnUNetTrainer.on_train_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataloaders()\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwas_initialized:\n\u001b[0;32m--> 906\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m maybe_mkdir_p(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_folder)\n\u001b[1;32m    910\u001b[0m \u001b[38;5;66;03m# make sure deep supervision is on in the network\u001b[39;00m\n",
      "File \u001b[0;32m/home/bhatti_uhn/nnU-net/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:210\u001b[0m, in \u001b[0;36mnnUNetTrainer.initialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwas_initialized:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_input_channels \u001b[38;5;241m=\u001b[39m determine_num_input_channels(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplans_manager, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfiguration_manager,\n\u001b[1;32m    208\u001b[0m                                                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_json)\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_network_architecture\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfiguration_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork_arch_class_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfiguration_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork_arch_init_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfiguration_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork_arch_init_kwargs_req_import\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_input_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_segmentation_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_deep_supervision\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# compile network for free speedup\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_i_compile():\n",
      "File \u001b[0;32m/home/bhatti_uhn/nnU-net/nnunetv2/training/nnUNetTrainer/nnUnetSegClsTrainer.py:41\u001b[0m, in \u001b[0;36mnnUnetSegClsTrainer.build_network_architecture\u001b[0;34m(architecture_class_name, arch_init_kwargs, arch_init_kwargs_req_import, num_input_channels, num_output_channels, enable_deep_supervision)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_deep_supervision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeep_supervision\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m arch_init_kwargs\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     39\u001b[0m     arch_init_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeep_supervision\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m enable_deep_supervision\n\u001b[0;32m---> 41\u001b[0m network \u001b[38;5;241m=\u001b[39m \u001b[43mSegClsNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_input_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_output_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marchitecture_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(network, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitialize\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m     network\u001b[38;5;241m.\u001b[39mapply(network\u001b[38;5;241m.\u001b[39minitialize)\n",
      "\u001b[0;31mTypeError\u001b[0m: SegClsNet.__init__() got multiple values for argument 'n_stages'"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "# Define the necessary arguments\n",
    "# args = [\n",
    "#     \"script_name\",  # This is a placeholder for the script name\n",
    "#     \"Dataset876_UHNMedImg3D\",  # dataset_name_or_id\n",
    "#     \"3d_fullres\",  # configuration\n",
    "#     f\"{fold}\",  # fold\n",
    "#     # '-tr', 'nnUNetTrainer',  # optional: trainer_class_name\n",
    "#     # '-p', 'nnUNetPlans',  # optional: plans_identifier\n",
    "# ]\n",
    "\n",
    "args = [\n",
    "    \"script_name\",  # This is a placeholder for the script name\n",
    "    \"Dataset876_UHNMedImg3D\",  # dataset_name_or_id\n",
    "    \"3d_fullres\",  # configuration\n",
    "    f\"{fold}\",  # fold\n",
    "    '-tr', 'nnUnetSegClsTrainer',  # optional: trainer_class_name\n",
    "    # '-p', 'nnUNetPlans',  # optional: plans_identifier\n",
    "]\n",
    "\n",
    "# Set sys.argv to the list of arguments\n",
    "sys.argv = args\n",
    "\n",
    "# Run the training entry function\n",
    "run_training_entry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "Fingerprint extraction...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uhn_venv/bin/nnUNetv2_plan_and_preprocess\", line 8, in <module>\n",
      "    sys.exit(plan_and_preprocess_entry())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bhatti_uhn/nnU-net/nnunetv2/experiment_planning/plan_and_preprocess_entrypoints.py\", line 180, in plan_and_preprocess_entry\n",
      "    extract_fingerprints(args.d, args.fpe, args.npfp, args.verify_dataset_integrity, args.clean, args.verbose)\n",
      "  File \"/home/bhatti_uhn/nnU-net/nnunetv2/experiment_planning/plan_and_preprocess_api.py\", line 47, in extract_fingerprints\n",
      "    extract_fingerprint_dataset(d, fingerprint_extractor_class, num_processes, check_dataset_integrity, clean,\n",
      "  File \"/home/bhatti_uhn/nnU-net/nnunetv2/experiment_planning/plan_and_preprocess_api.py\", line 26, in extract_fingerprint_dataset\n",
      "    dataset_name = convert_id_to_dataset_name(dataset_id)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bhatti_uhn/nnU-net/nnunetv2/utilities/dataset_name_id_conversion.py\", line 48, in convert_id_to_dataset_name\n",
      "    raise RuntimeError(f\"Could not find a dataset with the ID {dataset_id}. Make sure the requested dataset ID \"\n",
      "RuntimeError: Could not find a dataset with the ID 876. Make sure the requested dataset ID exists and that nnU-Net knows where raw and preprocessed data are located (see Documentation - Installation). Here are your currently defined folders:\n",
      "nnUNet_preprocessed=None\n",
      "nnUNet_results=None\n",
      "nnUNet_raw=None\n",
      "If something is not right, adapt your environment variables.\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_plan_and_preprocess -d 876 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming your dataset has 'images' and 'labels' subdirectories\n",
    "# move_and_rename_files(os.path.join(base_dir, 'images'), images_tr_dir, 'patient')\n",
    "# move_and_rename_files(os.path.join(base_dir, 'labels'), labels_tr_dir, 'patient', is_label=True)\n",
    "\n",
    "# # Create dataset.json\n",
    "# dataset_json = {\n",
    "#     \"name\": \"UHNMedImg3D\",\n",
    "#     \"description\": \"UHN Medical Imaging 3D Machine Learning Quiz Dataset\",\n",
    "#     \"tensorImageSize\": \"4D\",\n",
    "#     \"reference\": \"\",\n",
    "#     \"licence\": \"\",\n",
    "#     \"release\": \"0.0\",\n",
    "#     \"modality\": {\n",
    "#         \"0\": \"CT\"\n",
    "#     },\n",
    "#     \"labels\": {\n",
    "#         \"0\": \"background\",\n",
    "#         \"1\": \"label1\",\n",
    "#         \"2\": \"label2\"\n",
    "#     },\n",
    "#     \"numTraining\": len(os.listdir(images_tr_dir)),\n",
    "#     \"numTest\": 0,  # Update this if you have test images\n",
    "#     \"training\": [\n",
    "#         {\n",
    "#             \"image\": f\"./imagesTr/patient_{i+1:03d}_0000.nii.gz\",\n",
    "#             \"label\": f\"./labelsTr/patient_{i+1:03d}.nii.gz\"\n",
    "#         } for i in range(len(os.listdir(images_tr_dir)))\n",
    "#     ],\n",
    "#     \"test\": []  # Update this if you have test images\n",
    "# }\n",
    "\n",
    "# # Save dataset.json\n",
    "# with open(os.path.join(nnunet_base, 'dataset.json'), 'w') as f:\n",
    "#     json.dump(dataset_json, f, indent=4)\n",
    "\n",
    "# print(\"Dataset arranged successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uhn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
